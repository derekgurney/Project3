{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library imports and file definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using complete file\n",
      "/Users/DerekAtWork/Google Drive/Data Science/Udacity/Project3.Data Wrangling with MongoDB/vancouver_canada.osm\n",
      "/Users/DerekAtWork/Google Drive/Data Science/Udacity/Project3.Data Wrangling with MongoDB/vancouver_canada.osm.json\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import codecs\n",
    "import json\n",
    "\n",
    "directory = '/Users/DerekAtWork/Google Drive/Data Science/Udacity/Project3.Data Wrangling with MongoDB/'\n",
    "#directory = '/Users/DerekAtWork/GitHub/Udacity/Project3'\n",
    "\n",
    "#sample = True\n",
    "sample = False\n",
    "\n",
    "if sample:\n",
    "    print \"Using sample\"\n",
    "    osmfile = directory + 'sample.osm'\n",
    "    jsonfile = osmfile + \".json\"  \n",
    "else:\n",
    "    print \"Using complete file\"\n",
    "    osmfile = directory + 'vancouver_canada.osm'\n",
    "    jsonfile = osmfile + \".json\"\n",
    "print osmfile\n",
    "print jsonfile\n",
    "filename = osmfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for creating sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import xml.etree.ElementTree as ET  # Use cElementTree or lxml if too slow\n",
    "'''\n",
    "\n",
    "OSM_FILE = osmfile  # Replace this with your osm file\n",
    "SAMPLE_FILE = directory + \"sample.osm\"\n",
    "\n",
    "k = 20 # Parameter: take every k-th top level element\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\n",
    "\n",
    "    Reference:\n",
    "    http://stackoverflow.com/questions/3095434/inserting-newlines-in-xml-file-generated-via-xml-etree-elementtree-in-python\n",
    "    \"\"\"\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "with open(SAMPLE_FILE, 'wb') as output:\n",
    "    output.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write('<osm>\\n  ')\n",
    "\n",
    "    # Write every kth top level element\n",
    "    for i, element in enumerate(get_element(OSM_FILE)):\n",
    "        if i % k == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write('</osm>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Types\n",
    "[Same as Lesson 6 code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /Users/DerekAtWork/Google Drive/Data Science/Udacity/Project3.Data Wrangling with MongoDB/vancouver_canada.osm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lower': 235553, 'lower_colon': 25803, 'other': 2851, 'problemchars': 2}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Your task is to explore the data a bit more.\n",
    "Before you process the data and add it into MongoDB, you should check the \"k\"\n",
    "value for each \"<tag>\" and see if they can be valid keys in MongoDB, as well as\n",
    "see if there are any other potential problems.\n",
    "\n",
    "We have provided you with 3 regular expressions to check for certain patterns\n",
    "in the tags. As we saw in the quiz earlier, we would like to change the data\n",
    "model and expand the \"addr:street\" type of keys to a dictionary like this:\n",
    "{\"address\": {\"street\": \"Some value\"}}\n",
    "So, we have to see if we have such tags, and if we have any tags with\n",
    "problematic characters.\n",
    "\n",
    "Please complete the function 'key_type', such that we have a count of each of\n",
    "four tag categories in a dictionary:\n",
    "  \"lower\", for tags that contain only lowercase letters and are valid,\n",
    "  \"lower_colon\", for otherwise valid tags with a colon in their names,\n",
    "  \"problemchars\", for tags with problematic characters, and\n",
    "  \"other\", for other tags that do not fall into the other three categories.\n",
    "See the 'process_map' and 'test' functions for examples of the expected format.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        # Note to self: This is code I added to template\n",
    "        key = element.get(\"k\") \n",
    "        #print key\n",
    "        if re.match(lower, key): #Note to self: match starting from beginning of string\n",
    "            keys[\"lower\"] += 1\n",
    "            #keys[\"lower\"].append(key)\n",
    "            #print key\n",
    "        elif re.match(lower_colon, key): \n",
    "            keys[\"lower_colon\"]  += 1\n",
    "            #keys[\"lower_colon\"].append(key)\n",
    "            #print key\n",
    "        elif  re.search(problemchars, key): #search anywhere\n",
    "            keys[\"problemchars\"]  += 1\n",
    "            #keys[\"problemchars\"].append(key)\n",
    "             #print key\n",
    "        else:\n",
    "            keys[\"other\"]  += 1\n",
    "\n",
    "                #keys[\"other\"].append(key) \n",
    "                #print key       \n",
    "    return keys\n",
    "\n",
    "\n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "    return keys\n",
    "\n",
    "print \"Using \" + osmfile\n",
    "process_map(osmfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Users\n",
    "[Same as Lesson 6 code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_user(element):\n",
    "    return\n",
    "\n",
    "\n",
    "def process_map(filename):\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        pass\n",
    "        if element.tag == \"node\":\n",
    "            user = element.get(\"user\") \n",
    "            if user not in users:\n",
    "                users.add(user) #Pedagogical note: not users.append(user) because users is a set, not a dict\n",
    "\n",
    "    return users\n",
    "\n",
    "pprint.pprint(process_map(osmfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auditing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audit complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "############ Street types\n",
    "\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "expected_street = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Alley\", \"Broadway\", \"Walk\",\"Crescent\", \"Esplanade\", \"Highway\",\"Kingsway\",\"Mews\",\"Mall\",\"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"South\",\"Commons\",\"Way\",\"West\",\"East\"]\n",
    "\n",
    "mapping_street = { \"Blvd\": \"Boulevard\",\n",
    "            \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Rd.\": \"Road\",\n",
    "            \"Steet\": \"Street\",\n",
    "            \"street\": \"Street\",\n",
    "            \"venue\": \"Avenue\",\n",
    "            \"Broughton\": \"Broughton Street\",\n",
    "            \"Jervis\": \"Jervis Street\",\n",
    "            \"Jarvis\": \"Jervis Street\"\n",
    "            }\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    '''If the street type is not in the list of expected types, adds the type to a dictionary.'''\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected_street:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "\n",
    "def is_street_name(elem):\n",
    "    '''Checks if elem.attrib['k'] is addr:street.'''\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "############ City Names\n",
    "\n",
    "expected_city = ['Vancouver', 'North Vancouver', 'Richmond','North Vancouver City']\n",
    "\n",
    "mapping_city = { \"Vancovuer\": \"Vancouver\",\n",
    "            \"vancouver\": \"Vancouver\",\n",
    "            }\n",
    "\n",
    "def audit_city_name(city_names, city_name):\n",
    "    '''If the city name is not in the list of expected cities, adds the city to a dictionary.'''\n",
    "    if city_name not in expected_city:\n",
    "        city_names[city_name].add(city_name)\n",
    "\n",
    "def is_city_name(elem):\n",
    "    '''Checks if elem.attrib['k'] is addr:city.'''\n",
    "    return (elem.attrib['k'] == \"addr:city\")\n",
    "\n",
    "\n",
    "############ Province\n",
    "expected_prov = ['British Columbia']\n",
    "\n",
    "mapping_prov = { \"BC\": \"British Columbia\",\n",
    "            \"B.C.\": \"British Columbia\",\n",
    "            \"bc\": \"British Columbia\",\n",
    "            }\n",
    "\n",
    "def audit_prov_name(prov_names, prov_name):\n",
    "    '''If the province is not in the list of expected provinces, adds the province to a dictionary.'''\n",
    "    if prov_name not in expected_prov:\n",
    "        prov_names[prov_name].add(prov_name)\n",
    "\n",
    "def is_prov_name(elem):\n",
    "    '''Checks if elem.attrib['k'] is addr:province.'''    \n",
    "    return (elem.attrib['k'] == \"addr:province\")\n",
    "\n",
    "############ Postal Codes\n",
    "\n",
    "mapping_postalcodes = defaultdict(set)\n",
    "\n",
    "postalcode_valid_except_caps = re.compile(r'[a-z][5|6|7][a-z][ ][0-9][a-z][0-9]$')\n",
    "postalcode_valid_except_spacing_and_possibly_caps = re.compile(r'[A-Za-z][5|6|7][A-Za-z][0-9][A-Za-z][0-9]$')\n",
    "\n",
    "def audit_postal_code(postal_codes, postal_code):\n",
    "    '''If the postal code is valid but for specific formatting issues, fix formatting.'''\n",
    "    if postalcode_valid_except_caps.search(postal_code):\n",
    "        postal_codes[postal_code].add(postal_code)\n",
    "        mapping_postalcodes[postal_code] = postal_code.upper()\n",
    "    elif postalcode_valid_except_spacing_and_possibly_caps.search(postal_code):\n",
    "        postal_codes[postal_code].add(postal_code)\n",
    "        mapping_postalcodes[postal_code] = postal_code[0:3].upper() + \" \" + postal_code[3:6].upper()\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "def is_postal_code(elem):\n",
    "    '''Checks if elem.attrib['k'] is addr:postcode.'''    \n",
    "    return (elem.attrib['k'] == \"addr:postcode\")\n",
    "\n",
    "\n",
    "############ MAIN AUDIT\n",
    "\n",
    "def audit(osmfile):\n",
    "    '''Reads osmfile and returns a dictionaries of unexpected entries for the following:\n",
    "    Street types (Drive, Road, etc..)\n",
    "    City names\n",
    "    Province names\n",
    "    Postal codes.'''\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    city_names = defaultdict(set)\n",
    "    prov_names = defaultdict(set)\n",
    "    postal_codes = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "                if is_city_name(tag):\n",
    "                    audit_city_name(city_names, tag.attrib['v'])\n",
    "                if is_prov_name(tag):\n",
    "                    audit_prov_name(prov_names, tag.attrib['v'])\n",
    "                if is_postal_code(tag):\n",
    "                    audit_postal_code(postal_codes, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types, city_names, prov_names, postal_codes\n",
    "\n",
    "def update_name_with_mapping(name, mapping):\n",
    "\n",
    "    for key, value in mapping.iteritems():\n",
    "        key_at_end = re.escape(key) + r\"$\"\n",
    "        name = re.sub(key_at_end, value, name)\n",
    "\n",
    "    return name\n",
    "\n",
    "st_types, cty_names, prv_names, pstl_codes = audit(osmfile)\n",
    "print 'Audit complete'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Street Types updating\n",
    "[Same as Lesson 6 code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2nd': set(['East 2nd']),\n",
      " '3305': set(['Expo Blvd, #3305']),\n",
      " 'Ave': set(['West 3rd Ave', 'West 41st Ave']),\n",
      " 'Broughton': set(['Broughton']),\n",
      " 'Jarvis': set(['Jarvis']),\n",
      " 'Jervis': set(['Jervis']),\n",
      " 'Luna': set(['Gen. Luna']),\n",
      " 'Pojezierska': set(['Pojezierska']),\n",
      " 'Rd.': set(['Boundary Rd.']),\n",
      " 'St': set(['Beatty St',\n",
      "            'East Pender St',\n",
      "            'Nicola St',\n",
      "            'Robson St',\n",
      "            'West Pender St',\n",
      "            'Whitchurch St',\n",
      "            'Yew St']),\n",
      " 'St.': set(['Mainland St.', 'Seymour St.']),\n",
      " 'Steet': set(['West Hastings Steet']),\n",
      " u'S\\u0142oneczna': set([u'S\\u0142oneczna']),\n",
      " 'Terminal': set(['Station Terminal']),\n",
      " 'Vancouver': set(['Howe St. Vancouver', 'W. Hastings St. Vancouver']),\n",
      " 'Venue': set(['Greer Venue']),\n",
      " 'street': set(['Main street'])}\n",
      "('Station Terminal', 'Station Terminal')\n",
      "('Boundary Rd.', 'Boundary Road')\n",
      "(u'S\\u0142oneczna', u'S\\u0142oneczna')\n",
      "('Jervis', 'Jervis Street')\n",
      "('Mainland St.', 'Mainland Street')\n",
      "('Seymour St.', 'Seymour Street')\n",
      "('Greer Venue', 'Greer Venue')\n",
      "('Nicola St', 'Nicola Street')\n",
      "('East Pender St', 'East Pender Street')\n",
      "('West Pender St', 'West Pender Street')\n",
      "('Robson St', 'Robson Street')\n",
      "('Yew St', 'Yew Street')\n",
      "('Whitchurch St', 'Whitchurch Street')\n",
      "('Beatty St', 'Beatty Street')\n",
      "('East 2nd', 'East 2nd')\n",
      "('Gen. Luna', 'Gen. Luna')\n",
      "('Main street', 'Main Street')\n",
      "('W. Hastings St. Vancouver', 'W. Hastings St. Vancouver')\n",
      "('Howe St. Vancouver', 'Howe St. Vancouver')\n",
      "('Pojezierska', 'Pojezierska')\n",
      "('Broughton', 'Broughton Street')\n",
      "('West Hastings Steet', 'West Hastings Street')\n",
      "('West 41st Ave', 'West 41st AAvenue')\n",
      "('West 3rd Ave', 'West 3rd AAvenue')\n",
      "('Expo Blvd, #3305', 'Expo Blvd, #3305')\n",
      "('Jarvis', 'Jervis Street')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(dict(st_types))\n",
    "for st_type, ways in st_types.iteritems():\n",
    "    for name in ways:\n",
    "        better_name = update_name_with_mapping(name, mapping_street)\n",
    "        print(name, better_name) \n",
    "        '''Note: there isn't a mapping for \n",
    "        every unexpected entry, so some better names will be unchanged from name '''\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing City Names updating\n",
    "[Adapted from Lesson 6 code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Alfonso': set(['Alfonso']),\n",
      " 'Dresden': set(['Dresden']),\n",
      " 'Edenbridge': set(['Edenbridge']),\n",
      " 'Kirchberg an der Raab': set(['Kirchberg an der Raab']),\n",
      " 'Legnica': set(['Legnica']),\n",
      " 'Lexington': set(['Lexington']),\n",
      " 'Lubatowa': set(['Lubatowa']),\n",
      " 'Nieuw Nickerie': set(['Nieuw Nickerie']),\n",
      " 'Nova Friburgo': set(['Nova Friburgo']),\n",
      " 'Taguig': set(['Taguig']),\n",
      " 'Vancouver, BC': set(['Vancouver, BC']),\n",
      " 'Vancovuer': set(['Vancovuer']),\n",
      " 'Winsted': set(['Winsted']),\n",
      " 'north vancouver': set(['north vancouver']),\n",
      " 'vancouver': set(['vancouver']),\n",
      " u'\\u0141\\xf3d\\u017a': set([u'\\u0141\\xf3d\\u017a']),\n",
      " u'\\u0415\\u043a\\u0430\\u0442\\u0435\\u0440\\u0438\\u043d\\u0431\\u0443\\u0440\\u0433': set([u'\\u0415\\u043a\\u0430\\u0442\\u0435\\u0440\\u0438\\u043d\\u0431\\u0443\\u0440\\u0433']),\n",
      " u'\\u0422\\u0440\\u0435\\u0442\\u0438\\u0439 \\u0421\\u0435\\u0432\\u0435\\u0440\\u043d\\u044b\\u0439': set([u'\\u0422\\u0440\\u0435\\u0442\\u0438\\u0439 \\u0421\\u0435\\u0432\\u0435\\u0440\\u043d\\u044b\\u0439']),\n",
      " u'\\u8c4a\\u5ddd\\u5e02': set([u'\\u8c4a\\u5ddd\\u5e02'])}\n",
      "Łódź Łódź\n",
      "Dresden Dresden\n",
      "Третий Северный Третий Северный\n",
      "Nieuw Nickerie Nieuw Nickerie\n",
      "Legnica Legnica\n",
      "Lubatowa Lubatowa\n",
      "Lexington Lexington\n",
      "Nova Friburgo Nova Friburgo\n",
      "豊川市 豊川市\n",
      "Taguig Taguig\n",
      "vancouver Vancouver\n",
      "Alfonso Alfonso\n",
      "Екатеринбург Екатеринбург\n",
      "Winsted Winsted\n",
      "Kirchberg an der Raab Kirchberg an der Raab\n",
      "Edenbridge Edenbridge\n",
      "Vancouver, BC Vancouver, BC\n",
      "Vancovuer Vancouver\n",
      "north vancouver north Vancouver\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(dict(cty_names))\n",
    "for cty_name, ways in cty_names.iteritems():\n",
    "    for name in ways:\n",
    "        better_name = update_name_with_mapping(name, mapping_city)\n",
    "        print name, better_name \n",
    "        '''Note: there isn't a mapping for \n",
    "        every unexpected entry, so some better names will be unchanged from name '''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Province Name updating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B.C.': set(['B.C.']),\n",
      " 'BC': set(['BC']),\n",
      " 'Cavite': set(['Cavite']),\n",
      " 'Kent': set(['Kent']),\n",
      " 'ON': set(['ON']),\n",
      " 'bc': set(['bc']),\n",
      " u'\\u611b\\u77e5\\u770c': set([u'\\u611b\\u77e5\\u770c'])}\n",
      "ON ON\n",
      "bc British Columbia\n",
      "BC British Columbia\n",
      "愛知県 愛知県\n",
      "Cavite Cavite\n",
      "Kent Kent\n",
      "B.C. British Columbia\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(dict(prv_names))\n",
    "for prv_name, ways in prv_names.iteritems():\n",
    "    for name in ways:\n",
    "        better_name = update_name_with_mapping(name, mapping_prov)\n",
    "        print name, better_name \n",
    "        '''Note: there isn't a mapping for \n",
    "        every unexpected entry, so some better names will be unchanged from name '''\n",
    "#'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Post Codes updating\n",
    "[Adapted from Auditing City Name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'V5K3A6': set(['V5K3A6']),\n",
      " 'V5K3K3': set(['V5K3K3']),\n",
      " 'V5K5C5': set(['V5K5C5']),\n",
      " 'V5L1K5': set(['V5L1K5']),\n",
      " 'V5L1V3': set(['V5L1V3']),\n",
      " 'V5L2K8': set(['V5L2K8']),\n",
      " 'V5M3K5': set(['V5M3K5']),\n",
      " 'V5N2H7': set(['V5N2H7']),\n",
      " 'V5N2S9': set(['V5N2S9']),\n",
      " 'V5N3P9': set(['V5N3P9']),\n",
      " 'V5R5M2': set(['V5R5M2']),\n",
      " 'V5T1R6': set(['V5T1R6']),\n",
      " 'V5T2K4': set(['V5T2K4']),\n",
      " 'V5T4T6': set(['V5T4T6']),\n",
      " 'V5V3R5': set(['V5V3R5']),\n",
      " 'V5X3L6': set(['V5X3L6']),\n",
      " 'V5X4R6': set(['V5X4R6']),\n",
      " 'V5Y4B1': set(['V5Y4B1']),\n",
      " 'V5Z0A2': set(['V5Z0A2']),\n",
      " 'V5Z1M9': set(['V5Z1M9']),\n",
      " 'V5Z1N2': set(['V5Z1N2']),\n",
      " 'V5Z1N3': set(['V5Z1N3']),\n",
      " 'V5Z2L5': set(['V5Z2L5']),\n",
      " 'V5Z2L7': set(['V5Z2L7']),\n",
      " 'V5Z2R3': set(['V5Z2R3']),\n",
      " 'V5Z2S1': set(['V5Z2S1']),\n",
      " 'V5Z2S4': set(['V5Z2S4']),\n",
      " 'V5Z3M5': set(['V5Z3M5']),\n",
      " 'V5Z3M9': set(['V5Z3M9']),\n",
      " 'V5Z3N2': set(['V5Z3N2']),\n",
      " 'V5Z3N5': set(['V5Z3N5']),\n",
      " 'V5Z3N6': set(['V5Z3N6']),\n",
      " 'V5Z3S2': set(['V5Z3S2']),\n",
      " 'V6B0G6': set(['V6B0G6']),\n",
      " 'V6B1G6': set(['V6B1G6']),\n",
      " 'V6B1H7': set(['V6B1H7']),\n",
      " 'V6B2J1': set(['V6B2J1']),\n",
      " 'V6B2N4': set(['V6B2N4']),\n",
      " 'V6E1N4': set(['V6E1N4']),\n",
      " 'V6E2P4': set(['V6E2P4']),\n",
      " 'V6G1X5': set(['V6G1X5']),\n",
      " 'V6G1Y7': set(['V6G1Y7']),\n",
      " 'V6G2W3': set(['V6G2W3']),\n",
      " 'V6G3E3': set(['V6G3E3']),\n",
      " 'V6H1L6': set(['V6H1L6']),\n",
      " 'V6H2K5': set(['V6H2K5']),\n",
      " 'V6H2R2': set(['V6H2R2']),\n",
      " 'V6H2R5': set(['V6H2R5']),\n",
      " 'V6H3J7': set(['V6H3J7']),\n",
      " 'V6J0E2': set(['V6J0E2']),\n",
      " 'V6J1M3': set(['V6J1M3']),\n",
      " 'V6J3H1': set(['V6J3H1']),\n",
      " 'V6J5G4': set(['V6J5G4']),\n",
      " 'V6K4T4': set(['V6K4T4']),\n",
      " 'V6M1L8': set(['V6M1L8']),\n",
      " 'V6M1L9': set(['V6M1L9']),\n",
      " 'V6M1M1': set(['V6M1M1']),\n",
      " 'V6M1M2': set(['V6M1M2']),\n",
      " 'V6M1M3': set(['V6M1M3']),\n",
      " 'V6M1P6': set(['V6M1P6']),\n",
      " 'V6M1P8': set(['V6M1P8']),\n",
      " 'V6M1P9': set(['V6M1P9']),\n",
      " 'V6M1R4': set(['V6M1R4']),\n",
      " 'V6M1S7': set(['V6M1S7']),\n",
      " 'V6M1S9': set(['V6M1S9']),\n",
      " 'V6M1T1': set(['V6M1T1']),\n",
      " 'V6M1V1': set(['V6M1V1']),\n",
      " 'V6M1V2': set(['V6M1V2']),\n",
      " 'V6M1V3': set(['V6M1V3']),\n",
      " 'V6M1V5': set(['V6M1V5']),\n",
      " 'V6M1W8': set(['V6M1W8']),\n",
      " 'V6M1X1': set(['V6M1X1']),\n",
      " 'V6M1X2': set(['V6M1X2']),\n",
      " 'V6M1X4': set(['V6M1X4']),\n",
      " 'V6M1X5': set(['V6M1X5']),\n",
      " 'V6M2A8': set(['V6M2A8']),\n",
      " 'V6M2B8': set(['V6M2B8']),\n",
      " 'V6M2G8': set(['V6M2G8']),\n",
      " 'V6M2H1': set(['V6M2H1']),\n",
      " 'V6M2P7': set(['V6M2P7']),\n",
      " 'V6M2V5': set(['V6M2V5']),\n",
      " 'V6M2W7': set(['V6M2W7']),\n",
      " 'V6M2W9': set(['V6M2W9']),\n",
      " 'V6M2X2': set(['V6M2X2']),\n",
      " 'V6M2X4': set(['V6M2X4']),\n",
      " 'V6M2Y5': set(['V6M2Y5']),\n",
      " 'V6M2Z1': set(['V6M2Z1']),\n",
      " 'V6M2Z2': set(['V6M2Z2']),\n",
      " 'V6M2Z4': set(['V6M2Z4']),\n",
      " 'V6M3A3': set(['V6M3A3']),\n",
      " 'V6M3A5': set(['V6M3A5']),\n",
      " 'V6M3A6': set(['V6M3A6']),\n",
      " 'V6M4J6': set(['V6M4J6']),\n",
      " 'V6P3M4': set(['V6P3M4']),\n",
      " 'V6R3S5': set(['V6R3S5']),\n",
      " 'V6T1L9': set(['V6T1L9']),\n",
      " 'V6T1Z1': set(['V6T1Z1']),\n",
      " 'V6T1Z3': set(['V6T1Z3']),\n",
      " 'V6Z1M1': set(['V6Z1M1']),\n",
      " 'V6Z1M4': set(['V6Z1M4']),\n",
      " 'V6Z1R2': set(['V6Z1R2']),\n",
      " 'V6Z2T9': set(['V6Z2T9']),\n",
      " 'V7L0B2': set(['V7L0B2']),\n",
      " 'V7L2A4': set(['V7L2A4']),\n",
      " 'V7Y1E8': set(['V7Y1E8']),\n",
      " 'v5l4t6': set(['v5l4t6']),\n",
      " 'v5t 4r8': set(['v5t 4r8']),\n",
      " 'v5y 3w3': set(['v5y 3w3']),\n",
      " 'v6z 2b7': set(['v6z 2b7']),\n",
      " 'v7m 2e8': set(['v7m 2e8'])}\n",
      "V6M2W9 V6M 2W9\n",
      "V5Z0A2 V5Z 0A2\n",
      "V5Z2R3 V5Z 2R3\n",
      "V6M2W7 V6M 2W7\n",
      "V5L2K8 V5L 2K8\n",
      "V6G2W3 V6G 2W3\n",
      "V6H2K5 V6H 2K5\n",
      "V7L2A4 V7L 2A4\n",
      "V5T4T6 V5T 4T6\n",
      "V6T1Z1 V6T 1Z1\n",
      "V6M1M2 V6M 1M2\n",
      "V6M1M1 V6M 1M1\n",
      "v6z 2b7 V6Z 2B7\n",
      "V6H2R5 V6H 2R5\n",
      "V6H2R2 V6H 2R2\n",
      "v7m 2e8 V7M 2E8\n",
      "V6M2X4 V6M 2X4\n",
      "V6M2X2 V6M 2X2\n",
      "V6M3A5 V6M 3A5\n",
      "V6M2G8 V6M 2G8\n",
      "V6M3A6 V6M 3A6\n",
      "V6M3A3 V6M 3A3\n",
      "V6M2V5 V6M 2V5\n",
      "V6M1R4 V6M 1R4\n",
      "V5Z2L5 V5Z 2L5\n",
      "V5Z2L7 V5Z 2L7\n",
      "V5Z3S2 V5Z 3S2\n",
      "V5L1V3 V5L 1V3\n",
      "V5Y4B1 V5Y 4B1\n",
      "V6M1M3 V6M 1M3\n",
      "V6M1S9 V6M 1S9\n",
      "V5Z1M9 V5Z 1M9\n",
      "V6T1Z3 V6T 1Z3\n",
      "V6J1M3 V6J 1M3\n",
      "V6M1S7 V6M 1S7\n",
      "V6B2N4 V6B 2N4\n",
      "V6G1Y7 V6G 1Y7\n",
      "V5N3P9 V5N 3P9\n",
      "V5Z2S4 V5Z 2S4\n",
      "v5l4t6 V5L 4T6\n",
      "V5R5M2 V5R 5M2\n",
      "V5Z1N2 V5Z 1N2\n",
      "V5Z1N3 V5Z 1N3\n",
      "V5Z3N2 V5Z 3N2\n",
      "V6B0G6 V6B 0G6\n",
      "V5Z3N6 V5Z 3N6\n",
      "V5Z3N5 V5Z 3N5\n",
      "v5t 4r8 V5T 4R8\n",
      "V5T1R6 V5T 1R6\n",
      "V7Y1E8 V7Y 1E8\n",
      "V7L0B2 V7L 0B2\n",
      "V6J0E2 V6J 0E2\n",
      "V6B1G6 V6B 1G6\n",
      "V6Z1M1 V6Z 1M1\n",
      "V6J3H1 V6J 3H1\n",
      "V6M1X4 V6M 1X4\n",
      "V6M1X5 V6M 1X5\n",
      "V6P3M4 V6P 3M4\n",
      "V6M1X1 V6M 1X1\n",
      "V6M1X2 V6M 1X2\n",
      "V6M1P6 V6M 1P6\n",
      "V6M1P8 V6M 1P8\n",
      "V6M1P9 V6M 1P9\n",
      "V6M1V5 V6M 1V5\n",
      "V6M1V2 V6M 1V2\n",
      "V6M1V3 V6M 1V3\n",
      "V6M1V1 V6M 1V1\n",
      "V5T2K4 V5T 2K4\n",
      "V6M1W8 V6M 1W8\n",
      "V6J5G4 V6J 5G4\n",
      "V5K3K3 V5K 3K3\n",
      "V5X4R6 V5X 4R6\n",
      "V6Z2T9 V6Z 2T9\n",
      "V5V3R5 V5V 3R5\n",
      "V6R3S5 V6R 3S5\n",
      "V6M2B8 V6M 2B8\n",
      "V5N2H7 V5N 2H7\n",
      "V6E2P4 V6E 2P4\n",
      "V5Z3M5 V5Z 3M5\n",
      "V5K5C5 V5K 5C5\n",
      "V5Z3M9 V5Z 3M9\n",
      "V5L1K5 V5L 1K5\n",
      "V5M3K5 V5M 3K5\n",
      "V6B2J1 V6B 2J1\n",
      "V6K4T4 V6K 4T4\n",
      "V6M4J6 V6M 4J6\n",
      "V5X3L6 V5X 3L6\n",
      "V6H1L6 V6H 1L6\n",
      "V6M2A8 V6M 2A8\n",
      "V6M2Z4 V6M 2Z4\n",
      "V6M2Z1 V6M 2Z1\n",
      "V6M2Z2 V6M 2Z2\n",
      "V6M1T1 V6M 1T1\n",
      "V6H3J7 V6H 3J7\n",
      "V6Z1R2 V6Z 1R2\n",
      "V6M2P7 V6M 2P7\n",
      "V5Z2S1 V5Z 2S1\n",
      "V5K3A6 V5K 3A6\n",
      "V6E1N4 V6E 1N4\n",
      "V5N2S9 V5N 2S9\n",
      "V6M2H1 V6M 2H1\n",
      "V6T1L9 V6T 1L9\n",
      "V6G1X5 V6G 1X5\n",
      "V6G3E3 V6G 3E3\n",
      "V6Z1M4 V6Z 1M4\n",
      "V6M1L8 V6M 1L8\n",
      "V6M1L9 V6M 1L9\n",
      "V6B1H7 V6B 1H7\n",
      "v5y 3w3 V5Y 3W3\n",
      "V6M2Y5 V6M 2Y5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pprint.pprint(dict(pstl_codes))\n",
    "for pstl_code, ways in pstl_codes.iteritems():\n",
    "    for name in ways:\n",
    "        better_name = update_name_with_mapping(name, mapping_postalcodes)\n",
    "        print name, better_name \n",
    "\n",
    "        #Note: there isn't a mapping for \n",
    "        #every unexpected entry, so some better names will be unchanged from name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for printing out file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shape_element(element):\n",
    "    print element\n",
    "    if element.tag == \"node\" or element.tag == \"way\" or element.tag == \"relation\" :\n",
    "        for key, value in element.attrib.iteritems():\n",
    "            print 'key', 'value', key, value\n",
    "        \n",
    "\n",
    "        for child in element:\n",
    "            print 'child', child\n",
    "            for key, value in child.attrib.iteritems():\n",
    "                print \"key, value\", key, value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for preparing for MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "\n",
    "\n",
    "def shape_element(element):\n",
    "    node = {}\n",
    "    if element.tag == \"node\" or element.tag == \"way\" :\n",
    "        # Note to self: This is code I added to template\n",
    "        this_created = {}\n",
    "        node['type'] = element.tag\n",
    "        # based on https://discussions.udacity.com/t/my-code-is-not-finding-a-specific-tag-attribute/157674/5\n",
    "        \n",
    "        for key, value in element.attrib.iteritems():\n",
    "            #attributes in the CREATED array should be added under a key \"created\"\n",
    "            #attributes for latitude and longitude should be added to a \"pos\" array,for use in geospacial indexing. Make sure the values inside \"pos\" array are floats and not strings. \n",
    "            created_list = ['version','changeset','timestamp','user','uid']\n",
    "            if key in created_list:\n",
    "                this_created[key] = element.attrib[key]\n",
    "            \n",
    "            elif key == 'lon':\n",
    "                pass      # will be dealt with in 'lat' \n",
    "            elif key == 'lat': \n",
    "                node['pos'] = [float(element.attrib['lat']), float(element.attrib['lon'])]          \n",
    "            else:\n",
    "                node[key] = value\n",
    "        node['created'] = this_created\n",
    "        if element.tag == \"way\":\n",
    "            node['node_refs'] = []\n",
    "                \n",
    "            #if the second level tag \"k\" value starts with \"addr:\", it should be added to a dictionary \"address\"\n",
    "        this_address = {}\n",
    "        keyfornode = \"\"\n",
    "        for child in element: #note: not an interior loop of above, though \n",
    "            for key, value in child.attrib.iteritems():\n",
    "                #if the second level tag \"k\" value contains problematic characters, it should be ignored\n",
    "                if 'k' in child.attrib: #make sure that there is a key tag\n",
    "                    if  re.search(problemchars, child.attrib['k']):     \n",
    "                        print \"k Has problem chars: \", child.attrib['k']\n",
    "                    elif re.match('addr:',child.attrib['k']): #if k tag starts with addr:\n",
    "                        if child.attrib['k'].count(':') > 1: #if k tag has 2 colons, ignore\n",
    "                            pass\n",
    "                        else: #\n",
    "                            temp = child.attrib['k'].split(':')[1]\n",
    "                            if temp == 'street':\n",
    "                                this_address[temp] = update_name_with_mapping(child.attrib['v'], mapping_street)\n",
    "                            elif temp == 'city':\n",
    "                                this_address[temp] = update_name_with_mapping(child.attrib['v'], mapping_city)\n",
    "                            elif temp == 'province':\n",
    "                                this_address[temp] = update_name_with_mapping(child.attrib['v'], mapping_prov)\n",
    "                            elif temp == 'postcode':\n",
    "                                this_address[temp] = update_name_with_mapping(child.attrib['v'], mapping_postalcodes)\n",
    "                            else:\n",
    "                                this_address[temp] = child.attrib['v']\n",
    "                            #start here\n",
    "                    \n",
    "                    elif child.attrib['k'].count(':') > 0: #if k tag does not start with addr: but has a colon\n",
    "                        if child.attrib['k'].count(':') > 1: #if k tag has 2 colons, ignore\n",
    "                            pass\n",
    "                        else:\n",
    "                            # capture the content before the colon\n",
    "                            if keyfornode == \"\" or keyfornode != child.attrib['k'].split(':')[0]:\n",
    "                                keyfornode = child.attrib['k'].split(':')[0]\n",
    "                                this_other = {}\n",
    "                            subkey = child.attrib['k'].split(':')[1]\n",
    "                            this_other[subkey] = child.attrib['v']\n",
    "                            node[keyfornode] = this_other #update\n",
    "                    else:\n",
    "                        node[child.attrib['k']] = child.attrib['v']\n",
    "                elif 'ref' in child.attrib:\n",
    "                    node['node_refs'].append(child.attrib['ref'])\n",
    "                elif 'v' not in child.attrib:\n",
    "                     print 'the child.attrib is something other than k, v, or ref: ', child.attrib\n",
    "                   \n",
    "                else:\n",
    "                    pass\n",
    "        if this_address: #if this_address is not empty\n",
    "            node['address'] = this_address\n",
    "\n",
    "        \n",
    "        return node\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Code for dumping to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_map(file_in, pretty = False):\n",
    "    # Note from Udacity: You do not need to change this file\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "    data = []\n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "        for _, element in ET.iterparse(file_in):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                data.append(el)\n",
    "                if pretty:\n",
    "                    fo.write(json.dumps(el, indent=2)+\"\\n\")\n",
    "                else:\n",
    "                    fo.write(json.dumps(el) + \"\\n\")\n",
    "    return data\n",
    "data = process_map(osmfile, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
