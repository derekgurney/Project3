{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning ideas\n",
    "* province\n",
    "\n",
    "* postal code\n",
    "* area code\n",
    "* city names\n",
    "* those fix mes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library imports and file definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sample\n",
      "sample.osm\n",
      "sample.osm.json\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import codecs\n",
    "import json\n",
    "\n",
    "sample = True\n",
    "#sample = False\n",
    "\n",
    "if sample:\n",
    "    print \"Using sample\"\n",
    "    osmfile = 'sample.osm'\n",
    "    jsonfile = osmfile + \".json\"  \n",
    "else:\n",
    "    #osmfile = '~/Google Drive/Data Science/Udacity/Project3.Data Wrangling with MongoDB/vancouver_canada.osm'\n",
    "    print \"Using complete file\"\n",
    "    osmfile = 'vancouver_canada.osm'\n",
    "    jsonfile = osmfile + \".json\"\n",
    "print osmfile\n",
    "print jsonfile\n",
    "filename = osmfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for creating sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import xml.etree.ElementTree as ET  # Use cElementTree or lxml if too slow\n",
    "\n",
    "OSM_FILE = \"vancouver_canada.osm\"  # Replace this with your osm file\n",
    "SAMPLE_FILE = \"sample.osm\"\n",
    "\n",
    "k = 20 # Parameter: take every k-th top level element\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\n",
    "\n",
    "    Reference:\n",
    "    http://stackoverflow.com/questions/3095434/inserting-newlines-in-xml-file-generated-via-xml-etree-elementtree-in-python\n",
    "    \"\"\"\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "with open(SAMPLE_FILE, 'wb') as output:\n",
    "    output.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write('<osm>\\n  ')\n",
    "\n",
    "    # Write every kth top level element\n",
    "    for i, element in enumerate(get_element(OSM_FILE)):\n",
    "        if i % k == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write('</osm>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Your task is to explore the data a bit more.\n",
    "Before you process the data and add it into MongoDB, you should check the \"k\"\n",
    "value for each \"<tag>\" and see if they can be valid keys in MongoDB, as well as\n",
    "see if there are any other potential problems.\n",
    "\n",
    "We have provided you with 3 regular expressions to check for certain patterns\n",
    "in the tags. As we saw in the quiz earlier, we would like to change the data\n",
    "model and expand the \"addr:street\" type of keys to a dictionary like this:\n",
    "{\"address\": {\"street\": \"Some value\"}}\n",
    "So, we have to see if we have such tags, and if we have any tags with\n",
    "problematic characters.\n",
    "\n",
    "Please complete the function 'key_type', such that we have a count of each of\n",
    "four tag categories in a dictionary:\n",
    "  \"lower\", for tags that contain only lowercase letters and are valid,\n",
    "  \"lower_colon\", for otherwise valid tags with a colon in their names,\n",
    "  \"problemchars\", for tags with problematic characters, and\n",
    "  \"other\", for other tags that do not fall into the other three categories.\n",
    "See the 'process_map' and 'test' functions for examples of the expected format.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        # YOUR CODE HERE\n",
    "        #pass        '''\n",
    "        key = element.get(\"k\") \n",
    "        #print key\n",
    "        if re.match(lower, key): #match starting from beginning of string\n",
    "            keys[\"lower\"] += 1\n",
    "            #keys[\"lower\"].append(key)\n",
    "            #print key\n",
    "        elif re.match(lower_colon, key): \n",
    "            keys[\"lower_colon\"]  += 1\n",
    "            #keys[\"lower_colon\"].append(key)\n",
    "            #print key\n",
    "        elif  re.search(problemchars, key): #search anywhere\n",
    "            keys[\"problemchars\"]  += 1\n",
    "            #keys[\"problemchars\"].append(key)\n",
    "             #print key\n",
    "        else:\n",
    "            keys[\"other\"]  += 1\n",
    "\n",
    "                #keys[\"other\"].append(key) \n",
    "                #print key       \n",
    "    return keys\n",
    "\n",
    "\n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "    return keys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lower': 235553, 'lower_colon': 25803, 'other': 2851, 'problemchars': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_map(osmfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_user(element):\n",
    "    return\n",
    "\n",
    "\n",
    "def process_map(filename):\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        pass\n",
    "        if element.tag == \"node\":\n",
    "            user = element.get(\"user\") \n",
    "            if user not in users:\n",
    "                users.add(user) #not users.append(user) because users is a set, not a dict\n",
    "\n",
    "    return users\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([None,\n",
      "     '2bre99',\n",
      "     '4b696d',\n",
      "     '7503146',\n",
      "     '>LAND',\n",
      "     'ACervantes',\n",
      "     'AKC',\n",
      "     'Aaron Hilton',\n",
      "     'Achilnos',\n",
      "     'Adam Dunn',\n",
      "     'AdamWill',\n",
      "     'Alan',\n",
      "     'Alan Trick',\n",
      "     'Aleks-Berlin',\n",
      "     'Alex Cruise',\n",
      "     'AmateurCartographer',\n",
      "     'AndiG88',\n",
      "     'Andre68',\n",
      "     'Andrea428',\n",
      "     'AndyGibb',\n",
      "     'Anthony Steele',\n",
      "     'Anton Lavrov',\n",
      "     'Aquin',\n",
      "     'Art Olin',\n",
      "     'Arthur Chan',\n",
      "     'BC Hiker',\n",
      "     'BCBiker',\n",
      "     'Bellbellbell',\n",
      "     'Blaireo',\n",
      "     'BlaneG',\n",
      "     'Blobo123',\n",
      "     'Bootprint',\n",
      "     'Brandon5228',\n",
      "     'BruceMap',\n",
      "     'Bryce C Nesbitt',\n",
      "     'BuganiniQ',\n",
      "     'Bullroarer',\n",
      "     'Burrito!',\n",
      "     'C2H0',\n",
      "     'CBDVN',\n",
      "     'CJ60',\n",
      "     'Cababunga',\n",
      "     'CamD',\n",
      "     'CamJW',\n",
      "     'CamNZ',\n",
      "     'CandyFu',\n",
      "     'ChrissW-R1',\n",
      "     'Cicerone',\n",
      "     'Claudius Henrichs',\n",
      "     'CloCkWeRX',\n",
      "     'Cobra',\n",
      "     'Concession',\n",
      "     'CoreyBurger',\n",
      "     'Creando',\n",
      "     'DENelson83',\n",
      "     'DKazzed',\n",
      "     'DMDK',\n",
      "     'DPTRob',\n",
      "     'Dami_Tn',\n",
      "     'DangNgu',\n",
      "     'Danielos94',\n",
      "     'David & Christine Schmitt',\n",
      "     'David Huang',\n",
      "     'David Metcalfe',\n",
      "     'DeniskMikhailov',\n",
      "     'DevManning',\n",
      "     'DoesTheMoonAlsoFall',\n",
      "     'Drdul',\n",
      "     'DuaneElverum',\n",
      "     'Elmo Yu',\n",
      "     'Emarsee',\n",
      "     'Enene',\n",
      "     'Evantime',\n",
      "     'Evelyn Chen',\n",
      "     'Federico Mena Quintero',\n",
      "     'Floydm',\n",
      "     'Francois Marier',\n",
      "     'FvGordon',\n",
      "     'GJSchofield',\n",
      "     'GVRD',\n",
      "     'Geogast',\n",
      "     'GerdP',\n",
      "     'Glassman',\n",
      "     'GoogleMapMaker',\n",
      "     'Green Lake Studio',\n",
      "     'GreenGeographer',\n",
      "     'Hai-Etlik',\n",
      "     'Hawk777',\n",
      "     'HeyFaulk',\n",
      "     'HolgerJeromin',\n",
      "     'Homlett',\n",
      "     'Homsar123',\n",
      "     'Idcmp',\n",
      "     'Iron Beaver',\n",
      "     'JGairns',\n",
      "     'JMolnar',\n",
      "     'Jallensauce',\n",
      "     'JamesB93',\n",
      "     'JamesCopeland',\n",
      "     'JeffJSmith',\n",
      "     'JeffTaylor',\n",
      "     'Jens von Bergmann',\n",
      "     'Jepau',\n",
      "     'JesseVader08',\n",
      "     \"Jim O'Leary\",\n",
      "     'Jochen Topf',\n",
      "     'JoeDuffy90',\n",
      "     'Joel Carter',\n",
      "     'John Kroeker',\n",
      "     'JohnnyDooley',\n",
      "     'Jon Strait',\n",
      "     'Joni1101',\n",
      "     'Josef73',\n",
      "     'Jou64',\n",
      "     'Jubilo Haku',\n",
      "     'KaabiStar',\n",
      "     'KamiCrit',\n",
      "     'Kamil Kisiel',\n",
      "     'KaranM',\n",
      "     'Koinonen',\n",
      "     'L0ken',\n",
      "     'LS_Gossau',\n",
      "     'Larifari77',\n",
      "     'Latze',\n",
      "     'Lawn Gnome',\n",
      "     'Liam Whalen',\n",
      "     'Lindymap',\n",
      "     'Linnea Harder',\n",
      "     'Little Brother',\n",
      "     'LivingWithDragons',\n",
      "     'LucasMedaffy',\n",
      "     'Luke Vivier',\n",
      "     'MB MIGRATION',\n",
      "     'MBartsch',\n",
      "     'MNoo',\n",
      "     'Maggie Yu',\n",
      "     'Manu1400',\n",
      "     'MappityDoo',\n",
      "     'Marcott',\n",
      "     'Markus59',\n",
      "     'Martin Feucht',\n",
      "     'MaryBennett',\n",
      "     'Math1985',\n",
      "     'Mathiasdm',\n",
      "     'Medevac71',\n",
      "     'Meliora Cogito',\n",
      "     'MelioraCogito',\n",
      "     'MetVanRider123acme',\n",
      "     'Michi',\n",
      "     'MikaelN',\n",
      "     'Mike Moody',\n",
      "     'Mike@BC',\n",
      "     'Mo Quinn',\n",
      "     'MonicaW',\n",
      "     'Murphy',\n",
      "     'MuzikMachine',\n",
      "     'NE2',\n",
      "     'Natfoot',\n",
      "     'NathanCH',\n",
      "     'Nautic',\n",
      "     'Neil M',\n",
      "     'Nicholas Fong',\n",
      "     'Nicolas Untz',\n",
      "     'Nihat',\n",
      "     'NoVa mapper',\n",
      "     'North Van Man',\n",
      "     'NuttyNutter',\n",
      "     'OSMF Redaction Account',\n",
      "     'Omnific',\n",
      "     'Oplopanax',\n",
      "     'PFriedrichS',\n",
      "     'PanoWorks',\n",
      "     'Paradox352',\n",
      "     'Paul Johnson',\n",
      "     'Paul Ramsey',\n",
      "     'Pepper',\n",
      "     'Peter Bzzz',\n",
      "     'Peter Eller',\n",
      "     'Peter14',\n",
      "     'PeterEastern',\n",
      "     'PhilB61',\n",
      "     'PlaneMad',\n",
      "     'Porfiry',\n",
      "     'Pronab Saha',\n",
      "     'QsoftStudios',\n",
      "     'Qualifirst Foods',\n",
      "     'R0bst3r',\n",
      "     'RAD',\n",
      "     'RBC123',\n",
      "     'RM87',\n",
      "     'RMorewood',\n",
      "     'RenSylvain',\n",
      "     'RetiredInNH',\n",
      "     'Rhondle',\n",
      "     'RichRico',\n",
      "     'RoadGeek_MD99',\n",
      "     'Roadrunner21',\n",
      "     'Rob Oost',\n",
      "     'RodrigoWarrior',\n",
      "     'Rps333',\n",
      "     'Rupert Swarbrick',\n",
      "     'Ryrainey',\n",
      "     'SP!KE',\n",
      "     'SRW',\n",
      "     'Saarang',\n",
      "     'SabineSW',\n",
      "     'Sam Dal Monte',\n",
      "     'ScottNelson',\n",
      "     'Serpens',\n",
      "     'Shannoncox',\n",
      "     'Shrinks99',\n",
      "     'Shuyan',\n",
      "     'Siegbaert',\n",
      "     'Signco',\n",
      "     'Simoneyes',\n",
      "     'SnowMeeper',\n",
      "     'SomeoneElse_Revert',\n",
      "     'Spacecookies',\n",
      "     'Spectrokid',\n",
      "     'Sphaerophoria',\n",
      "     'Stalfur',\n",
      "     'Stemby',\n",
      "     'Stephen Fung',\n",
      "     'Sundance',\n",
      "     'Sungsu',\n",
      "     'Sunhealth Clinic',\n",
      "     'Sven L',\n",
      "     'Syl',\n",
      "     'Tammy Jin PREC',\n",
      "     'Tantilus',\n",
      "     'TerraKendama',\n",
      "     'TheDutchMan13',\n",
      "     'The_Tom',\n",
      "     'Thibault ML',\n",
      "     'Thorseth',\n",
      "     'Todd Chisholm',\n",
      "     'TomRox',\n",
      "     'Tooben',\n",
      "     'Tovok7',\n",
      "     'TristanA',\n",
      "     'Tsonoqua',\n",
      "     'Tunnen',\n",
      "     'UBC TEST',\n",
      "     'UnChosen',\n",
      "     'VPOman',\n",
      "     'VanAdam',\n",
      "     'Vutu',\n",
      "     'WBSKI',\n",
      "     u'Walter Schl\\xf6gl',\n",
      "     'Wassup789',\n",
      "     'Wenhao Chen',\n",
      "     'WhiteMoose',\n",
      "     'Winston687',\n",
      "     'WonderSteve',\n",
      "     'World_Mapper',\n",
      "     'Xiaobo Wang',\n",
      "     'YVRBee',\n",
      "     'YogaNerd',\n",
      "     'YuruW',\n",
      "     'ZMWandelaar',\n",
      "     'Zandlopertje',\n",
      "     'ZzD7',\n",
      "     'a4audi4fun',\n",
      "     'a_fischer',\n",
      "     'abeckmann',\n",
      "     'abel801',\n",
      "     'adaviel',\n",
      "     'adjuva',\n",
      "     'ahalla',\n",
      "     'aharvey',\n",
      "     'ak1992',\n",
      "     'alarobric',\n",
      "     'alester',\n",
      "     'alester_imports',\n",
      "     'alexwarrior',\n",
      "     'alexz3',\n",
      "     'andrewboktor',\n",
      "     'andrewpmk',\n",
      "     'andygol',\n",
      "     'arcvancouver',\n",
      "     'arekushi',\n",
      "     'arteku',\n",
      "     'bbyrd',\n",
      "     'bennysdad',\n",
      "     'bibliothecar',\n",
      "     'billm2403',\n",
      "     'binhex',\n",
      "     'bitscoast',\n",
      "     'blaueva52h7jk',\n",
      "     'brchookolingo',\n",
      "     'brettcannon',\n",
      "     'bri g',\n",
      "     'brianh',\n",
      "     'bryceco',\n",
      "     'calfarome',\n",
      "     'casye',\n",
      "     'cdavila',\n",
      "     'cgaspoz',\n",
      "     'cgu66',\n",
      "     'charlescm',\n",
      "     'ciclista',\n",
      "     'clairehhlin',\n",
      "     'compdude',\n",
      "     'crisspu',\n",
      "     'crompton',\n",
      "     'csgisr',\n",
      "     'd3r3kk',\n",
      "     'dale_p',\n",
      "     'dannykath',\n",
      "     'darkoverlord',\n",
      "     'david105',\n",
      "     'dbaron',\n",
      "     'dcp',\n",
      "     'debbers',\n",
      "     'developingcountries',\n",
      "     'dhfinch',\n",
      "     'digicult',\n",
      "     'digitaldirect',\n",
      "     'dkmikea',\n",
      "     'dlewis',\n",
      "     'dmgroom',\n",
      "     'doviende',\n",
      "     'dpogue',\n",
      "     'dshkol',\n",
      "     'dtcaciuc',\n",
      "     'dtwong',\n",
      "     'dunbar loop',\n",
      "     'dustindauncey',\n",
      "     'dydychan',\n",
      "     'earlofspencer',\n",
      "     'ecnepsnai',\n",
      "     'ediyes',\n",
      "     'eehmke',\n",
      "     'elbatrop',\n",
      "     'emac',\n",
      "     'emptybits',\n",
      "     'eone',\n",
      "     'etp4eva',\n",
      "     'expandfurniture',\n",
      "     'fanthore',\n",
      "     'felipeedwards',\n",
      "     'findfreddy',\n",
      "     'finn1911',\n",
      "     'fissionchips',\n",
      "     'forrert',\n",
      "     'freemadc',\n",
      "     'freietonne-db',\n",
      "     'funvill',\n",
      "     'fx99',\n",
      "     'gary-prime',\n",
      "     'garynuss',\n",
      "     'gcamp',\n",
      "     'ge0freak',\n",
      "     'geodreieck4711',\n",
      "     'geoffengland',\n",
      "     'geoffsin',\n",
      "     'geozeisig',\n",
      "     'germin8',\n",
      "     'gfish',\n",
      "     'giggls',\n",
      "     'gindo89',\n",
      "     'gkornelson',\n",
      "     'gleissmap',\n",
      "     'gloria_cyb',\n",
      "     'gowlin',\n",
      "     'green-grover',\n",
      "     'gregus_',\n",
      "     'guegafue',\n",
      "     'hannaha',\n",
      "     'hanoj',\n",
      "     'hfourstu',\n",
      "     'hjonescox',\n",
      "     'hmpfgnrrr',\n",
      "     'hofoen',\n",
      "     'homebug',\n",
      "     'homerhsing',\n",
      "     'hpka',\n",
      "     'humbach',\n",
      "     'hyandrew',\n",
      "     'iLoveCrows',\n",
      "     'iainfromthelibrary',\n",
      "     'ij_',\n",
      "     'illoLab',\n",
      "     'imaginet',\n",
      "     'imnskp',\n",
      "     'iplat',\n",
      "     'irmatt',\n",
      "     'j-beda',\n",
      "     'jacobbraeutigam',\n",
      "     'jansenq',\n",
      "     'jaskoh',\n",
      "     'javafern',\n",
      "     'jaypeecee',\n",
      "     'jef',\n",
      "     'jharvey',\n",
      "     'jocehl',\n",
      "     'johncharlesdaly',\n",
      "     'johnnydangermond',\n",
      "     'jorge_o',\n",
      "     'jot',\n",
      "     'jpadams',\n",
      "     'jsattie',\n",
      "     'julianladisch',\n",
      "     'justinsulpico',\n",
      "     'jya86',\n",
      "     'k_re',\n",
      "     'kaitoe138',\n",
      "     'kakrueger',\n",
      "     'kalupa',\n",
      "     'kangaruu',\n",
      "     'karitotp',\n",
      "     'kartler175',\n",
      "     'kdickie',\n",
      "     'keithonearth',\n",
      "     'kelseydh',\n",
      "     'kelsiding',\n",
      "     'kelvinc',\n",
      "     'kerrygis',\n",
      "     'kevinglobal',\n",
      "     'kevlangton',\n",
      "     'kisaa',\n",
      "     'klusark',\n",
      "     'kmkrebs',\n",
      "     'kpelly',\n",
      "     'kuwako315',\n",
      "     'kyoshino',\n",
      "     'lachliggity',\n",
      "     'lasmasi',\n",
      "     'laurentr',\n",
      "     'lbuchy',\n",
      "     'leeching928',\n",
      "     'leeshoal',\n",
      "     'leuty',\n",
      "     'liamvancouver',\n",
      "     'liyuan85',\n",
      "     'ljjwfr',\n",
      "     'lnocheesse',\n",
      "     'lokejul',\n",
      "     'ltreed',\n",
      "     'lunafiko',\n",
      "     'macdonsp',\n",
      "     'mackb94',\n",
      "     'madison555',\n",
      "     'maggot27',\n",
      "     'maitrimover',\n",
      "     'malcolmh',\n",
      "     'mame-stgt',\n",
      "     'mapone',\n",
      "     'mappatman',\n",
      "     'marek kleciak',\n",
      "     'marionv',\n",
      "     'maryjs',\n",
      "     'mash84121',\n",
      "     'mashimaro',\n",
      "     'matteditmsts',\n",
      "     'mattropolis',\n",
      "     'mbiker',\n",
      "     'mbiker_imports_and_more',\n",
      "     'mcastagne',\n",
      "     'mcld',\n",
      "     'mdiener',\n",
      "     'mfagan',\n",
      "     'mhoulne',\n",
      "     'michael_moovelmaps',\n",
      "     'mk801',\n",
      "     'morray',\n",
      "     'mrehayden',\n",
      "     'muratc3',\n",
      "     'mwbrooks',\n",
      "     'myxor',\n",
      "     'normanm',\n",
      "     'nuckster',\n",
      "     'nuxper',\n",
      "     'oceanearth',\n",
      "     'ocgrace',\n",
      "     'ohayden',\n",
      "     'okrauth',\n",
      "     'oldenburg69',\n",
      "     'oldtopos',\n",
      "     'osm-pascal',\n",
      "     'oxy10',\n",
      "     'pacificIT',\n",
      "     'paulschw',\n",
      "     'pbryan',\n",
      "     'pcolli',\n",
      "     'pdunn',\n",
      "     'permute',\n",
      "     'peted',\n",
      "     'peterjohnson',\n",
      "     'petersfreeman',\n",
      "     'phoff',\n",
      "     'pnorman',\n",
      "     'pnorman_mechanical',\n",
      "     'pray4mojo',\n",
      "     'ptruchon',\n",
      "     'purple_circles',\n",
      "     'pyroshroom',\n",
      "     'qman57',\n",
      "     'rafm',\n",
      "     'raquo',\n",
      "     'rbrtwhite',\n",
      "     'rmarescu',\n",
      "     'rmikke',\n",
      "     'robbat2',\n",
      "     'robgeb',\n",
      "     'robidium',\n",
      "     'rudolf',\n",
      "     'rumpelsocke',\n",
      "     'runningcoffee',\n",
      "     'ruthmaben',\n",
      "     'sabbath0802',\n",
      "     'saikofish',\n",
      "     'samely',\n",
      "     'sandil64',\n",
      "     'sansell',\n",
      "     'sarahmprz',\n",
      "     'saynasadeghi',\n",
      "     'sbigelow',\n",
      "     'scotlande',\n",
      "     'sctrojan79',\n",
      "     'seattlefyi',\n",
      "     'skeskali',\n",
      "     'skl1',\n",
      "     'smendoza',\n",
      "     'sotypicat',\n",
      "     'srividya_c',\n",
      "     'staceyfriesen',\n",
      "     'still-a-worm',\n",
      "     'sushiboy',\n",
      "     't-i',\n",
      "     'teraflare',\n",
      "     'the506',\n",
      "     'tippobot',\n",
      "     'tixuwuoz',\n",
      "     'tnightingale',\n",
      "     'torpesco',\n",
      "     'tpaz1',\n",
      "     'tranalex',\n",
      "     'treeniti2',\n",
      "     'tunapeter',\n",
      "     'tynielson',\n",
      "     'uboot',\n",
      "     'user_5359',\n",
      "     'van Rees',\n",
      "     'vanbhills',\n",
      "     'vcelier',\n",
      "     'volz',\n",
      "     'werner2101',\n",
      "     'wheelmap_android',\n",
      "     'wheelmap_visitor',\n",
      "     'willsiddall',\n",
      "     'woodpeck_repair',\n",
      "     'wooster',\n",
      "     'xixi',\n",
      "     'xybot',\n",
      "     'yining wang',\n",
      "     'ypid',\n",
      "     'yukiko',\n",
      "     'z-dude',\n",
      "     'zeitgeist mentor',\n",
      "     'zephyr',\n",
      "     'zeromap',\n",
      "     'zhangrong5301'])\n"
     ]
    }
   ],
   "source": [
    "users = process_map(osmfile)\n",
    "pprint.pprint(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auditing Street Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OSMFILE = filename\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Alley\", \"Broadway\", \"Walk\",\"Crescent\", \"Esplanade\", \"Highway\",\"Kingsway\",\"Mews\",\"Mall\",\"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"South\",\"Commons\",\"Way\",\"West\",\"East\"]\n",
    "\n",
    "# UPDATE THIS VARIABLE\n",
    "mapping = { \"Blvd\": \"Boulevard\",\n",
    "            \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Rd.\": \"Road\",\n",
    "            \"Steet\": \"Street\",\n",
    "            \"street\": \"Street\",\n",
    "            \"venue\": \"Avenue\",\n",
    "            \"Broughton\": \"Broughton Street\",\n",
    "            \"Jervis\": \"Jervis Street\",\n",
    "            \"Jarvis\": \"Jervis Street\"\n",
    "            }\n",
    "\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "\n",
    "def update_name(name, mapping):\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    for key, value in mapping.iteritems():\n",
    "        key_at_end = re.escape(key) + r\"$\"\n",
    "        name = re.sub(key_at_end, value, name)\n",
    "\n",
    "    return name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "st_types = audit(osmfile)\n",
    "pprint.pprint(dict(st_types))\n",
    "for st_type, ways in st_types.iteritems():\n",
    "    for name in ways:\n",
    "        better_name = update_name(name, mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auditing City Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Vancovuer': set(['Vancovuer']),\n",
      " 'vancouver': set(['vancouver']),\n",
      " u'\\u0422\\u0440\\u0435\\u0442\\u0438\\u0439 \\u0421\\u0435\\u0432\\u0435\\u0440\\u043d\\u044b\\u0439': set([u'\\u0422\\u0440\\u0435\\u0442\\u0438\\u0439 \\u0421\\u0435\\u0432\\u0435\\u0440\\u043d\\u044b\\u0439'])}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "city_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "\n",
    "expected = ['Vancouver']\n",
    "\n",
    "# UPDATE THIS VARIABLE\n",
    "mapping = { \"Vancovuer\": \"Vancouver\",\n",
    "            \"vancouver\": \"Vancouver\",\n",
    "            }\n",
    "\n",
    "\n",
    "def audit_city_type(city_types, city_name):\n",
    "    m = city_type_re.search(city_name)\n",
    "    if m:\n",
    "        city_type = m.group()\n",
    "        if city_type not in expected:\n",
    "            city_types[city_type].add(city_name)\n",
    "\n",
    "\n",
    "def is_city_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:city\")\n",
    "\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    city_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_city_name(tag):\n",
    "                    audit_city_type(city_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return city_types\n",
    "\n",
    "\n",
    "def update_name(name, mapping):\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    for key, value in mapping.iteritems():\n",
    "        key_at_end = re.escape(key) + r\"$\"\n",
    "        name = re.sub(key_at_end, value, name)\n",
    "\n",
    "    return name\n",
    "\n",
    "#'''\n",
    "st_types = audit(osmfile)\n",
    "pprint.pprint(dict(st_types))\n",
    "for st_type, ways in st_types.iteritems():\n",
    "    for name in ways:\n",
    "        better_name = update_name(name, mapping)\n",
    "#'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auditing Province Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B.C.': set(['B.C.']),\n",
      " 'British Columbia': set(['British Columbia']),\n",
      " 'Cavite': set(['Cavite']),\n",
      " 'Kent': set(['Kent']),\n",
      " 'ON': set(['ON']),\n",
      " 'bc': set(['bc']),\n",
      " u'\\u611b\\u77e5\\u770c': set([u'\\u611b\\u77e5\\u770c'])}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "city_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "\n",
    "expected = ['British Columbia']\n",
    "\n",
    "# UPDATE THIS VARIABLE\n",
    "mapping = { \"B.C.\": \"British Columbia\",\n",
    "            \"bc\": \"British Columbia\",\n",
    "            }\n",
    "\n",
    "\n",
    "def audit_city_type(city_types, city_name):\n",
    "    #m = var_type_re.search(var_name)\n",
    "    m = city_name\n",
    "    if m:\n",
    "        #var_type = m.group()\n",
    "        city_type = city_name\n",
    "        if city_type not in expected:\n",
    "            city_types[city_type].add(city_name)\n",
    "\n",
    "\n",
    "def is_city_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:province\")\n",
    "\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    city_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_city_name(tag):\n",
    "                    audit_city_type(city_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return city_types\n",
    "\n",
    "\n",
    "def update_name(name, mapping):\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    for key, value in mapping.iteritems():\n",
    "        key_at_end = re.escape(key) + r\"$\"\n",
    "        name = re.sub(key_at_end, value, name)\n",
    "\n",
    "    return name\n",
    "\n",
    "#'''\n",
    "st_types = audit(osmfile)\n",
    "pprint.pprint(dict(st_types))\n",
    "for st_type, ways in st_types.iteritems():\n",
    "    for name in ways:\n",
    "        better_name = update_name(name, mapping)\n",
    "#'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auditing Postal Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'V5K3K3': set(['V5K3K3']),\n",
      " 'V5V3R5': set(['V5V3R5']),\n",
      " 'V5Z2R3': set(['V5Z2R3']),\n",
      " 'V6E2P4': set(['V6E2P4']),\n",
      " 'V6H2R2': set(['V6H2R2']),\n",
      " 'V6M1M3': set(['V6M1M3']),\n",
      " 'V6M3A5': set(['V6M3A5']),\n",
      " 'V6T1Z1': set(['V6T1Z1']),\n",
      " 'V6Z1R2': set(['V6Z1R2']),\n",
      " 'V6Z2T9': set(['V6Z2T9']),\n",
      " 'v5y 3w3': set(['v5y 3w3'])}\n",
      "V6E2P4 V6E 2P4\n",
      "V6Z1R2 V6Z 1R2\n",
      "V5Z2R3 V5Z 2R3\n",
      "V6M3A5 V6M 3A5\n",
      "V6Z2T9 V6Z 2T9\n",
      "V6T1Z1 V6T 1Z1\n",
      "V5K3K3 V5K 3K3\n",
      "V5V3R5 V5V 3R5\n",
      "V6M1M3 V6M 1M3\n",
      "v5y 3w3 V5Y 3W3\n",
      "V6H2R2 V6H 2R2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "var_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "expected_postalcodes_re = re.compile(r'V[5|6][A-Z] [0-9][A-Z][0-9]$')\n",
    "\n",
    "\n",
    "# UPDATE THIS VARIABLE\n",
    "mapping = { \"Vancovuer\": \"Vancouver\",\n",
    "            \"vancouver\": \"Vancouver\",\n",
    "            }\n",
    "\n",
    "\n",
    "def audit_var_type(var_types, var_name):\n",
    "    #m = var_type_re.search(var_name)\n",
    "    m = var_name\n",
    "    if m:\n",
    "        #var_type = m.group()\n",
    "        var_type = var_name\n",
    "        if not expected_postalcodes_re.search(var_name):\n",
    "            var_types[var_type].add(var_name)\n",
    "\n",
    "\n",
    "def is_var_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:postcode\")\n",
    "\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    var_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_var_name(tag):\n",
    "                    audit_var_type(var_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return var_types\n",
    "\n",
    "\n",
    "def update_name(name, mapping):\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    name = name.upper()\n",
    "    no_space_re = re.compile(r'V[5|6][A-Z][0-9][A-Z][0-9]$')\n",
    "    if no_space_re.search(name):\n",
    "        #insert a space into postal code\n",
    "        name = name[:3] + \" \" + name[3:]\n",
    "\n",
    "    return name\n",
    "\n",
    "#'''\n",
    "st_types = audit(osmfile)\n",
    "pprint.pprint(dict(st_types))\n",
    "for st_type, ways in st_types.iteritems():\n",
    "    for name in ways:\n",
    "        better_name = update_name(name, mapping)\n",
    "        print name, better_name\n",
    "#'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for printing out file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shape_element(element):\n",
    "    print element\n",
    "    if element.tag == \"node\" or element.tag == \"way\" or element.tag == \"relation\" :\n",
    "        for key, value in element.attrib.iteritems():\n",
    "            print 'key', 'value', key, value\n",
    "        \n",
    "\n",
    "        for child in element:\n",
    "            print 'child', child\n",
    "            for key, value in child.attrib.iteritems():\n",
    "                print \"key, value\", key, value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for preparing for MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "\n",
    "\n",
    "def shape_element(element):\n",
    "    node = {}\n",
    "    if element.tag == \"node\" or element.tag == \"way\" :\n",
    "        # YOUR CODE HERE\n",
    "        this_created = {}\n",
    "        node['type'] = element.tag\n",
    "        # based on https://discussions.udacity.com/t/my-code-is-not-finding-a-specific-tag-attribute/157674/5\n",
    "        \n",
    "        for key, value in element.attrib.iteritems():\n",
    "            #attributes in the CREATED array should be added under a key \"created\"\n",
    "            #attributes for latitude and longitude should be added to a \"pos\" array,for use in geospacial indexing. Make sure the values inside \"pos\" array are floats and not strings. \n",
    "            created_list = ['version','changeset','timestamp','user','uid']\n",
    "            if key in created_list:\n",
    "                this_created[key] = element.attrib[key]\n",
    "            \n",
    "            elif key == 'lon':\n",
    "                pass      # will be dealt with in 'lat' \n",
    "            elif key == 'lat': \n",
    "                node['pos'] = [float(element.attrib['lat']), float(element.attrib['lon'])]          \n",
    "            else:\n",
    "                node[key] = value\n",
    "        node['created'] = this_created\n",
    "        if element.tag == \"way\":\n",
    "            node['node_refs'] = []\n",
    "                \n",
    "            #if the second level tag \"k\" value starts with \"addr:\", it should be added to a dictionary \"address\"\n",
    "        this_address = {}\n",
    "        keyfornode = \"\"\n",
    "        for child in element: #note: not an interior loop of above, though \n",
    "            for key, value in child.attrib.iteritems():\n",
    "                #if the second level tag \"k\" value contains problematic characters, it should be ignored\n",
    "                if 'k' in child.attrib: #make sure that there is a key tag\n",
    "                    if  re.search(problemchars, child.attrib['k']):     \n",
    "                        #pass\n",
    "                        print \"k Has problem chars: \", child.attrib['k']\n",
    "                    elif re.match('addr:',child.attrib['k']): #if k tag starts with addr:\n",
    "                        if child.attrib['k'].count(':') > 1: #if k tag has 2 colons, ignore\n",
    "                            pass\n",
    "                        else:\n",
    "                            temp = child.attrib['k'].split(':')[1]\n",
    "                            this_address[temp] = child.attrib['v']\n",
    "                            #print this_address\n",
    "                    \n",
    "                    elif child.attrib['k'].count(':') > 0: #if k tag does not start with addr: but has a colon\n",
    "                        #pass\n",
    "                        \n",
    "                        #print 'k Has colon: ', child.attrib['k']\n",
    "                        if child.attrib['k'].count(':') > 1: #if k tag has 2 colons, ignore\n",
    "                            pass\n",
    "                        else:\n",
    "                            # capture the content before the colon\n",
    "                            if keyfornode == \"\" or keyfornode != child.attrib['k'].split(':')[0]:\n",
    "                                keyfornode = child.attrib['k'].split(':')[0]\n",
    "                                this_other = {}\n",
    "                            subkey = child.attrib['k'].split(':')[1]\n",
    "                            this_other[subkey] = child.attrib['v']\n",
    "                            node[keyfornode] = this_other #update\n",
    "                            #print this_address\n",
    "                    else:\n",
    "                        #pass\n",
    "                        #print 'k is something else: ', child.attrib['k']\n",
    "                        node[child.attrib['k']] = child.attrib['v']\n",
    "                elif 'ref' in child.attrib:\n",
    "                    node['node_refs'].append(child.attrib['ref'])\n",
    "                    #print node['node_refs']\n",
    "                elif 'v' not in child.attrib:\n",
    "                     print 'the child.attrib is something other than k, v, or ref: ', child.attrib\n",
    "                   \n",
    "                else:\n",
    "                    pass\n",
    "        if this_address: #if this_address is not empty\n",
    "            node['address'] = this_address\n",
    "\n",
    "        \n",
    "        #print node\n",
    "        return node\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code for dumping to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_map(file_in, pretty = False):\n",
    "    # You do not need to change this file\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "    data = []\n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "        for _, element in ET.iterparse(file_in):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                data.append(el)\n",
    "                if pretty:\n",
    "                    fo.write(json.dumps(el, indent=2)+\"\\n\")\n",
    "                else:\n",
    "                    fo.write(json.dumps(el) + \"\\n\")\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k Has problem chars:  Toll Free\n",
      "k Has problem chars:  Toll Free\n",
      "k Has problem chars:  addr.source:city\n",
      "k Has problem chars:  addr.source:city\n"
     ]
    }
   ],
   "source": [
    "data = process_map(osmfile, False)\n",
    "#need to send this to a file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/DerekAtWork/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:17: DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_id': ObjectId('570eb3418e573428046dfe6a'), u'name': u'Chicago'}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Your task is to sucessfully run the exercise to see how pymongo works\n",
    "and how easy it is to start using it.\n",
    "You don't actually have to change anything in this exercise,\n",
    "but you can change the city name in the add_city function if you like.\n",
    "\n",
    "Your code will be run against a MongoDB instance that we have provided.\n",
    "If you want to run this code locally on your machine,\n",
    "you have to install MongoDB (see Instructor comments for link to installation information)\n",
    "and uncomment the get_db function.\n",
    "\n",
    "Note: need to start mongodb in another terminal\n",
    "\"\"\"\n",
    "\n",
    "def insert_geo(infile, db):\n",
    "    data = process_file(infile)\n",
    "    # Add your code here. Insert the data in one command.\n",
    "    for d in data:\n",
    "        db.autos.insert(d)\n",
    "    \n",
    "def get_db():\n",
    "    # For local use\n",
    "    from pymongo import MongoClient\n",
    "    client = MongoClient('localhost:27017')\n",
    "    # 'examples' here is the database name. It will be created if it does not exist.\n",
    "    db = client.examples\n",
    "    return db\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # For local use\n",
    "    db = get_db() # uncomment this line if you want to run this locally\n",
    "    add_city(db)\n",
    "    print get_city(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing first 3 results\n",
      "\n",
      "{u'_id': ObjectId('571562eaa092e06eee9be2e6'),\n",
      " u'address': {u'housenumber': u'457',\n",
      "              u'postcode': u'V5Y 1R4',\n",
      "              u'street': u'West Broadway'},\n",
      " u'created': {u'changeset': u'26984530',\n",
      "              u'timestamp': u'2014-11-23T22:51:29Z',\n",
      "              u'uid': u'1408522',\n",
      "              u'user': u'Omnific',\n",
      "              u'version': u'6'},\n",
      " u'id': u'567129443',\n",
      " u'pos': [49.2633391, -123.11437],\n",
      " u'type': u'node'}\n",
      "{u'_id': ObjectId('571562eaa092e06eee9be2e7'),\n",
      " u'address': {u'housenumber': u'453',\n",
      "              u'postcode': u'V5Y 1R4',\n",
      "              u'street': u'West Broadway'},\n",
      " u'created': {u'changeset': u'20153277',\n",
      "              u'timestamp': u'2014-01-23T03:19:05Z',\n",
      "              u'uid': u'1891976',\n",
      "              u'user': u'AdamWill',\n",
      "              u'version': u'6'},\n",
      " u'id': u'567130209',\n",
      " u'pos': [49.263337, -123.1142702],\n",
      " u'type': u'node'}\n",
      "{u'_id': ObjectId('571562eaa092e06eee9be2e8'),\n",
      " u'address': {u'housenumber': u'445',\n",
      "              u'postcode': u'V5Y 1R4',\n",
      "              u'street': u'West Broadway'},\n",
      " u'created': {u'changeset': u'26984530',\n",
      "              u'timestamp': u'2014-11-23T22:51:29Z',\n",
      "              u'uid': u'1408522',\n",
      "              u'user': u'Omnific',\n",
      "              u'version': u'9'},\n",
      " u'id': u'567130365',\n",
      " u'pos': [49.2633407, -123.114038],\n",
      " u'type': u'node'}\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "\n",
    "Your task is to complete the 'porsche_query' function and in particular the query\n",
    "to find all autos where the manufacturer field matches \"Porsche\".\n",
    "Please modify only 'porsche_query' function, as only that will be taken into account.\n",
    "\n",
    "Your code will be run against a MongoDB instance that we have provided.\n",
    "If you want to run this code locally on your machine,\n",
    "you have to install MongoDB and download and insert the dataset.\n",
    "For instructions related to MongoDB setup and datasets please see Course Materials at\n",
    "the following link:\n",
    "https://www.udacity.com/wiki/ud032\n",
    "\"\"\"\n",
    "\n",
    "#replicate > db.yvr.find({\"address.street\" : \"West Broadway\"}).count()\n",
    "\n",
    "\n",
    "\n",
    "def bway_query():\n",
    "    # Please fill in the query to find all autos manuafactured by Porsche.\n",
    "    query = {\"address.street\" : \"West Broadway\"}\n",
    "    return query\n",
    "\n",
    "\n",
    "# Do not edit code below this line in the online code editor.\n",
    "# Code here is for local use on your own computer.\n",
    "def get_db(db_name):\n",
    "    # For local use\n",
    "    from pymongo import MongoClient\n",
    "    client = MongoClient('localhost:27017')\n",
    "    db = client[db_name]\n",
    "    return db\n",
    "\n",
    "def find_yvr(db, query):\n",
    "    # For local use\n",
    "    return db.yvr.find(query)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # For local use\n",
    "    db = get_db('geo')\n",
    "    query = bway_query()\n",
    "    results = find_yvr(db, query)\n",
    "\n",
    "    print \"Printing first 3 results\\n\"\n",
    "    import pprint\n",
    "    for street in results[:3]:\n",
    "        pprint.pprint(street)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "filter must be an instance of dict, bson.son.SON, or other type that inherits from collections.Mapping",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5af18e8f6db1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'geo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvyr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_yvr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Printing first 3 results\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-5b7e0809cfce>\u001b[0m in \u001b[0;36mfind_yvr\u001b[0;34m(db, query)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfind_yvr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# For local use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myvr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/DerekAtWork/anaconda/lib/python2.7/site-packages/pymongo/collection.pyc\u001b[0m in \u001b[0;36mfind\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mmongodoc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \"\"\"\n\u001b[0;32m-> 1137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mCursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_scan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_cursors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/DerekAtWork/anaconda/lib/python2.7/site-packages/pymongo/cursor.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, collection, filter, projection, skip, limit, no_cursor_timeout, cursor_type, sort, allow_partial_results, oplog_replay, modifiers, batch_size, manipulate)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mvalidate_is_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"filter\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"skip must be an instance of int\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/DerekAtWork/anaconda/lib/python2.7/site-packages/pymongo/common.pyc\u001b[0m in \u001b[0;36mvalidate_is_mapping\u001b[0;34m(option, value)\u001b[0m\n\u001b[1;32m    373\u001b[0m         raise TypeError(\"%s must be an instance of dict, bson.son.SON, or \"\n\u001b[1;32m    374\u001b[0m                         \u001b[0;34m\"other type that inherits from \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m                         \"collections.Mapping\" % (option,))\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: filter must be an instance of dict, bson.son.SON, or other type that inherits from collections.Mapping"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "def get_db(db_name):\n",
    "    # For local use\n",
    "    from pymongo import MongoClient\n",
    "    client = MongoClient('localhost:27017')\n",
    "    db = client[db_name]\n",
    "    return db\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # For local use\n",
    "    db = get_db('geo')\n",
    "    query = db.vyr.find().count()\n",
    "    results = find_yvr(db, query)\n",
    "\n",
    "    print \"Printing first 3 results\\n\"\n",
    "    import pprint\n",
    "    print results\n",
    "    #for street in results[:3]:\n",
    "        #pprint.pprint(street)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-b7993fd1b35c>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-b7993fd1b35c>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    mongoimport --db geo -c yvr --file vancouver_canada.osm.json\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#at mongo prompt:\n",
    "mongoimport --db geo -c yvr --file vancouver_canada.osm.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
